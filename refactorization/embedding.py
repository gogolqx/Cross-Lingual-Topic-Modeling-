# -*- coding: utf-8 -*-
"""Embedding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bPOBG1_37sPTisS7QsZKKJCc4_eTVb4d
"""

# !pip install -q sentencepiece
# !pip install -q tf_sentencepiece

# import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import tf_sentencepiece

# workaround for attribute error
# AttributeError: module 'tensorflow' has no attribute 'placeholder'
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

class Embedding():
  
  def __init__(self):
    # Set up graph.
    self.g = tf.Graph()
    with self.g.as_default():
        self.text_input = tf.placeholder(dtype = tf.string, shape = [None])
        self.en_de_embed = hub.Module("https://tfhub.dev/google/universal-sentence-encoder-xling/en-de/1")
        self.embedded_text = self.en_de_embed(self.text_input)
        self.init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])
    self.g.finalize()

    # Initialize session.
    self.session = tf.Session(graph = self.g)
    self.session.run(self.init_op)

  def get_embedding(self, sentences: np.array, print_every = 10000) -> np.array:
    total = len(sentences)
    print('Total iterations:', total)

    embeddings = []
    for i, s in zip(range(total), sentences):
      embeddings.append(self.session.run(self.embedded_text, feed_dict = {self.text_input: [s]}))
      
      if i % print_every == 0:
        print('Now:', i)
    return np.array(embeddings).squeeze()