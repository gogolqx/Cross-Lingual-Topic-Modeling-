# -*- coding: utf-8 -*-
"""KMeansClustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eOTqGHFiABtlB8yyNNvq4Q-Bsb2mP2n2
"""

import numpy as np
import sklearn
""" For KMeans clustering """
from sklearn.cluster import KMeans, MiniBatchKMeans
""" For graph plotting """
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import collections
""" For intercluster distance maps """
from yellowbrick.cluster import InterclusterDistance

class KMeansClustering():

  # def __init__(self, k, X, is_mini_batch = True, plot_bar_chart = True, show_intercluster_distance = False):
  def __init__(self, k, X, is_mini_batch = True, show_intercluster_distance = False):
    self.k = k
    self.n = len(X)
    self.X = np.array(X).reshape(self.n, 512)

    if show_intercluster_distance:
      """ For intercluster distance maps """
      if is_mini_batch:
        self.km = MiniBatchKMeans(n_clusters = k, init = 'k-means++', batch_size = 100, max_iter = 10000, compute_labels = True)
      else:
        self.km = KMeans(n_clusters = k, init = 'k-means++', max_iter = 10000)
      
      self.visualizer = InterclusterDistance(self.km).fit(self.X)
    else:
      if is_mini_batch:
        self.km = MiniBatchKMeans(n_clusters = k, init = 'k-means++', batch_size = 100, max_iter = 10000, compute_labels = True).fit(self.X)
      else:
        self.km = KMeans(n_clusters = k, init = 'k-means++', max_iter = 10000).fit(self.X)


    self.AIC = self.get_AIC()
    self.BIC = self.get_BIC()

    # self.cluster_data_index_dic = {}
    # 
    # for i, label in enumerate(self.km.labels_):
    #   if label not in self.cluster_data_index_dic:
    #     self.cluster_data_index_dic[label] = []
    #   self.cluster_data_index_dic[label].append(i)
    
    # if plot_bar_chart:
    #   self.print_frequency_by_clusters()
    #   self.print_frequency_by_clusters_and_source()


  def get_AIC(self):
    k, m = self.km.cluster_centers_.shape # dimension of centroids
    D = self.km.inertia_ # within-cluster sum of square distances, residual sum of squares 
    AIC = D + 2 * m * k
    return AIC

  def get_BIC(self):
    k, m = self.km.cluster_centers_.shape # dimension of centroids
    n = self.n
    D = self.km.inertia_ # within-cluster sum of square distances, residual sum of squares 
    # print(m, k, n, D)
    BIC = D + 0.5 * m * k * np.log(n)
    return BIC

  def print_frequency_by_clusters(self):
    dictionary = {}
    for label, datalist in self.cluster_data_index_dic.items():
      dictionary[label] = len(datalist)
    plt.bar(dictionary.keys(), dictionary.values(), width = 0.8, color = (0.2, 0.4, 0.6, 0.8))
    plt.xlabel('Clusters')
    plt.ylabel('Frequency')
    plt.title('Distribution of embeddings among clusters')
    plt.savefig(str(self.k) + 'ks-overall-bar.png')
    # files.download(str(self.k) + 'ks-overall-bar.png')

  def print_frequency_by_clusters_and_source(self, in_percentage = True):
    dictionary = {}
    for label, datalist in self.cluster_data_index_dic.items():
      dictionary[label] = {}
      dictionary[label]['nytimes'] = len(list(i for i in datalist if i < 77023))
      dictionary[label]['quora'] = len(list(i for i in datalist if 77023 <= i <= 136424))
      dictionary[label]['spiegel'] = len(list(i for i in datalist if i > 136424))
    dictionary = collections.OrderedDict(sorted(dictionary.items()))
    
    labels = dictionary.keys()
    if in_percentage:
      nytimes_feq = list(float("{:.1f}".format((counts['nytimes'] / 77023) * 100)) for counts in dictionary.values())
      quora_feq = list(float("{:.1f}".format((counts['quora'] / 59401) * 100)) for counts in dictionary.values()) # 59401 = 136424 - 77022
      spiegel_feq = list(float("{:.1f}".format((counts['spiegel'] / 217361) * 100)) for counts in dictionary.values()) # 217361 = 353785 - 136424
    else:
      nytimes_feq = list(counts['nytimes'] for counts in dictionary.values())
      quora_feq = list(counts['quora'] for counts in dictionary.values())
      spiegel_feq = list(counts['spiegel'] for counts in dictionary.values())

    # print('total % for nytimes, quora and spiegel respectively: ', sum(nytimes_feq), ' ', sum(quora_feq), ' ', sum(spiegel_feq))
    width = 0.26
    x = np.arange(len(labels))

    fig, ax = plt.subplots()
    rects1 = ax.bar(x - width, nytimes_feq, width, label = 'NYTimes', color = (0.21, 0.29, 0.50, 1.0))
    rects2 = ax.bar(x, quora_feq, width, label = 'Quora', color = (0.73, 0.31, 0.57, 1.0))
    rects3 = ax.bar(x + width, spiegel_feq, width, label = 'Die Spiegel', color = (1.0, 0.46, 0.29, 1.0))

    # Add some text for labels, title and custom x-axis tick labels, etc.
    ax.set_xlabel('Clusters')
    if in_percentage:
      ax.set_ylabel('Precentage by source')
      ax.set_title('Distribution of embeddings among clusters')
      ax.yaxis.set_major_formatter(mtick.PercentFormatter())
      # ax.set_ylim([0, 100])
    else:
      ax.set_ylabel('Frequency')
      ax.set_title('Distribution of embeddings among clusters and source')
    ax.set_xticks(x)
    ax.set_xticklabels(labels)
    ax.legend()

    def autolabel(rects):
        """Attach a text label above each bar in *rects*, displaying its height."""
        for rect in rects:
            height = rect.get_height()
            ax.annotate('{}'.format(height),
                        xy=(rect.get_x() + rect.get_width() / 2, height),
                        xytext=(0, 3),  # 3 points vertical offset
                        textcoords="offset points",
                        ha='center', va='bottom')
            
    autolabel(rects1)
    autolabel(rects2)
    autolabel(rects3)
    plt.savefig(str(self.k) + 'ks-grouped-bar.png')
    # files.download(str(self.k) + 'ks-grouped-bar.png')
    plt.show()